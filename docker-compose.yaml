networks:
  llava-net:

services:
  grafana:
    extends:
      file: .config/docker-compose-base.yaml
      service: grafana
    networks:
      - llava-net
    depends_on:
      - ollama

  ollama:
    image: ollama/ollama:0.6.8
    ports:
      - "11434:11434"
    volumes:
      - ./ollama:/root/.ollama
    networks:
      - llava-net
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_USE_MMAP=true             # Better memory management
      - OLLAMA_NUM_PARALLEL=8            # Match your 8-core CPU
      - OLLAMA_MAX_LOADED_MODELS=1       # Only keep 1 model in memory
      - OLLAMA_KEEP_ALIVE=5m             # Reduce keep-alive time
    deploy:
      resources:
        limits:
          cpus: '8.00'                   # Allocate all 8 cores
          memory: 16G                    # Leave 16GB for other processes
    tty: true
    entrypoint: ["/bin/sh", "/root/.ollama/run_ollama.sh"]
  
